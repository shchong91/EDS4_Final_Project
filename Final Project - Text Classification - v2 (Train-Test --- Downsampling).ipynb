{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Scikit-Learn\n",
    "\n",
    "### Content\n",
    "\n",
    "* Objective\n",
    "* Dataset\n",
    "* Data Preparation Using R\n",
    "* Data Exploration Using Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "#### To reduce the processing time of manual coding\n",
    "\n",
    "Open-end responses in a survey is always a great way to retrieve valuable information/ feedback from respondents. It allows respondents to express their thoughts and opinions through their own words. \n",
    "\n",
    "Manual coding is the most often way performed on the open-end responses so that the responses can be quantified and analysed in the same way as multiple response questions. \n",
    "\n",
    "However, manual coding is a very tedious and time consuming process as it requires coders to read and categorize each of the responses one by one.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "<img src=\"https://pinnacledealersolutions.net/wp-content/uploads/2017/05/blog-img-dealer-man-handships.jpg\", width=400>\n",
    "\n",
    "\n",
    "Customer Experience is key to success in automotive industry. \n",
    "The dataset that I'm using is the actual feedback/ comment from the customers about their dealership experience. \n",
    "\n",
    "Each feedback/comment will have a few classified categories (up to 8 categories) that were manually done by coder previously. So, I'm going to build a model to train on the labeled dataset with the pre-defined categories and feed the model with unseen data so that the model is able to classify them into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Using R\n",
    "\n",
    "#### Library\n",
    "    ibrary(plyr)\n",
    "\n",
    "#### Set Working Directory\n",
    "    setwd(\"C:\\\\Users\\\\SiowHui.Chong\\\\Desktop\\\\EDS4\\\\Enterprise_Data_Science4_EDS4\\\\Project\\\\Data\")\n",
    "\n",
    "#### Load Data from CSV\n",
    "    raw <- read.csv(\"DealershipExperience_1.csv\", header = TRUE, sep = \",\")\n",
    "<div class=\"alert alert-success\">\n",
    "Due to the encoding issue, i got special character (i..id) appended to the first variable in my first column, so I will rename my first column from \"i...id\" to \"id\".\n",
    "</div>\n",
    "    \n",
    "    names(raw)[1]<-\"id\"\n",
    "\n",
    "#### Data Preparation\n",
    "\n",
    "* Remove the double quote \" in string variable (feedback/comment) \n",
    "    \n",
    "    `raw <- as.data.frame(lapply(raw, function(x) gsub('\"', \"\", x)))`\n",
    "\n",
    "\n",
    "* Select all the categorical variables\n",
    "\n",
    "    `initialdf <- subset(raw, select = c(1,6:13))`\n",
    "    \n",
    "\n",
    "* Transform all the categories to individual columns \n",
    "\n",
    "<img src=\"./Data/DataViewfromR.JPG\", width=1000>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Create another list without the first column. Using apply loop to get the sequence of maximum value in all the rows and convert it to integer \n",
    "</div>  \n",
    "\n",
    "    seqlist <- apply(initialdf[-1], 1, function(x) as.integer(seq_len(max(x, na.rm = TRUE)) %in% x))\n",
    "<div class=\"alert alert-success\">\n",
    "Append NAs at the end of each row to make the lengths same in the list and combine back with the first column \n",
    "</div> \n",
    "\n",
    "    replacelist <- cbind(initialdf[1], do.call(rbind, lapply(seqlist, `length<-`, max(lengths(seqlist)))))\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Replace NAs with 0 \n",
    "</div> \n",
    "\n",
    "    replacelist[is.na(replacelist)] <- 0\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Rename the newly created columns to v1 (for category=1), v2 (for category=2), v55 (for category=55) etc.\n",
    "</div> \n",
    "\n",
    "    colnames(replacelist)[-1] <- paste0('v', 1:99)\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Remove columns without any categories\n",
    "</div> \n",
    "    \n",
    "    removedf <- replacelist[, colSums(replacelist != 0) > 0]\n",
    "    \n",
    "#### Merge transform data to original dataset Data to CSV\n",
    "    merged <- join(raw, removedf, by=\"id\")\n",
    "\n",
    "#### Export Data to CSV\n",
    "\n",
    "    write.table(merged, \"final.csv\", sep=\",\" ,row.names = FALSE, quote = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration Using Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Load Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/final.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>VisitedDealer</th>\n",
       "      <th>OtherDealerSatisfaction</th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>...</th>\n",
       "      <th>v64</th>\n",
       "      <th>v65</th>\n",
       "      <th>v70</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v73</th>\n",
       "      <th>v80</th>\n",
       "      <th>v81</th>\n",
       "      <th>v90</th>\n",
       "      <th>v97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>dodgy sales guy</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Good experience with them but they do not offe...</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>The sales person wasn`t very helpful in meetin...</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>Friendly and knowledgeable staff, just ended u...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>Helpful</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>All staff and service were excellent</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>Salesperson was friendly, went above &amp; beyond ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Not happy</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>Very well appointed showroom,  very friendly t...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>They were ok</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  QUARTER  VisitedDealer  OtherDealerSatisfaction  \\\n",
       "0   4        1             33                        7   \n",
       "1   5        1             23                        9   \n",
       "2   7        1             60                        9   \n",
       "3  10        1             46                        8   \n",
       "4  11        1             23                        8   \n",
       "5  13        1             22                       10   \n",
       "6  14        1             46                       10   \n",
       "7  16        1             23                        1   \n",
       "8  17        1             33                       10   \n",
       "9  19        1             40                        6   \n",
       "\n",
       "                                            Verbatim  C1   C2    C3  C4  C5  \\\n",
       "0                                    dodgy sales guy  60  NaN   NaN NaN NaN   \n",
       "1  Good experience with them but they do not offe...  63  NaN   NaN NaN NaN   \n",
       "2  The sales person wasn`t very helpful in meetin...  48  NaN   NaN NaN NaN   \n",
       "3  Friendly and knowledgeable staff, just ended u...   1  4.0   NaN NaN NaN   \n",
       "4                                            Helpful   2  NaN   NaN NaN NaN   \n",
       "5               All staff and service were excellent  32  NaN   NaN NaN NaN   \n",
       "6  Salesperson was friendly, went above & beyond ...   1  5.0   NaN NaN NaN   \n",
       "7                                          Not happy  81  NaN   NaN NaN NaN   \n",
       "8  Very well appointed showroom,  very friendly t...  26  1.0  16.0 NaN NaN   \n",
       "9                                       They were ok  32  NaN   NaN NaN NaN   \n",
       "\n",
       "  ...   v64  v65  v70  v71  v72  v73  v80  v81  v90  v97  \n",
       "0 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "1 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "2 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "3 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "4 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "5 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "6 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "7 ...     0    0    0    0    0    0    0    1    0    0  \n",
       "8 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "9 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[10 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to view first 10 rows of data\n",
    "data.head(10)\n",
    "#We can see that all the categories (v1 to v97) are binary variables (with class=0 or =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45403 entries, 0 to 45402\n",
      "Data columns (total 62 columns):\n",
      "id                         45403 non-null int64\n",
      "QUARTER                    45403 non-null int64\n",
      "VisitedDealer              45403 non-null int64\n",
      "OtherDealerSatisfaction    45403 non-null int64\n",
      "Verbatim                   45403 non-null object\n",
      "C1                         45403 non-null int64\n",
      "C2                         16688 non-null float64\n",
      "C3                         4482 non-null float64\n",
      "C4                         882 non-null float64\n",
      "C5                         177 non-null float64\n",
      "C6                         29 non-null float64\n",
      "C7                         6 non-null float64\n",
      "C8                         2 non-null float64\n",
      "v1                         45403 non-null int64\n",
      "v2                         45403 non-null int64\n",
      "v3                         45403 non-null int64\n",
      "v4                         45403 non-null int64\n",
      "v5                         45403 non-null int64\n",
      "v6                         45403 non-null int64\n",
      "v7                         45403 non-null int64\n",
      "v8                         45403 non-null int64\n",
      "v9                         45403 non-null int64\n",
      "v10                        45403 non-null int64\n",
      "v15                        45403 non-null int64\n",
      "v16                        45403 non-null int64\n",
      "v17                        45403 non-null int64\n",
      "v18                        45403 non-null int64\n",
      "v25                        45403 non-null int64\n",
      "v26                        45403 non-null int64\n",
      "v27                        45403 non-null int64\n",
      "v28                        45403 non-null int64\n",
      "v30                        45403 non-null int64\n",
      "v31                        45403 non-null int64\n",
      "v32                        45403 non-null int64\n",
      "v33                        45403 non-null int64\n",
      "v40                        45403 non-null int64\n",
      "v41                        45403 non-null int64\n",
      "v42                        45403 non-null int64\n",
      "v43                        45403 non-null int64\n",
      "v44                        45403 non-null int64\n",
      "v45                        45403 non-null int64\n",
      "v46                        45403 non-null int64\n",
      "v47                        45403 non-null int64\n",
      "v48                        45403 non-null int64\n",
      "v49                        45403 non-null int64\n",
      "v50                        45403 non-null int64\n",
      "v51                        45403 non-null int64\n",
      "v52                        45403 non-null int64\n",
      "v60                        45403 non-null int64\n",
      "v61                        45403 non-null int64\n",
      "v62                        45403 non-null int64\n",
      "v63                        45403 non-null int64\n",
      "v64                        45403 non-null int64\n",
      "v65                        45403 non-null int64\n",
      "v70                        45403 non-null int64\n",
      "v71                        45403 non-null int64\n",
      "v72                        45403 non-null int64\n",
      "v73                        45403 non-null int64\n",
      "v80                        45403 non-null int64\n",
      "v81                        45403 non-null int64\n",
      "v90                        45403 non-null int64\n",
      "v97                        45403 non-null int64\n",
      "dtypes: float64(7), int64(54), object(1)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#to list down all the information about dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to  create another new text variable for verbatim and change the type to string\n",
    "data['text'] = data['Verbatim'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to \"pre-process\" texts / words?\n",
    "\n",
    "* Remove all the numeric values from the texts\n",
    "* Convert all the texts to lowercase\n",
    "* Normalise the word to base form\n",
    "    \n",
    "    `PorterStemmer() WordNetLemmatizer()`\n",
    "<div class=\"alert alert-success\">  \n",
    "Lemmatization and stemming are special cases of normalization. \n",
    "The goal of both stemming and lemmatization is to identify a canonical representative for a set of related word forms to a common base form. \n",
    "</div> \n",
    "<div class=\"alert alert-success\">  \n",
    "Stemmer operates on a single word without knowledge of the context , and therefore cannot discriminate between words which have different meanings depending on part of speech.\n",
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words.\n",
    "<br>\n",
    "E.g. <br>\n",
    "The word \"better\" has \"good\" as its lemma. This link is missed by stemming, as it requires a dictionary look-up.\n",
    "<br>\n",
    "The word \"walk\" is the base form for word \"walking/waits/waited\", and hence this is matched in both stemming and lemmatisation.\n",
    "</div> \n",
    "\n",
    "\n",
    "* Count the occurrence of each word \n",
    "\n",
    "    `CountVectorizer=() TfidfVectorizer()`\n",
    "<div class=\"alert alert-success\">\n",
    "Texts / Comments are a series of words. In order to run machine learning algorithms,  we need to convert all the texts into into numerical feature vectors. We will have to segment each word respectively (splitting by space) and then count number of times each word occurs, and finally assign each word to an unique integer id. Each unique word will correspond to a feature.  (descriptive feature).\n",
    "</div> \n",
    "<div class=\"alert alert-success\">\n",
    "Using CountVectorizer from Scikit-learn will help to convert all words to matrix and count the count number of times each word occurs. TfidfVectorizer will assign different weights to every single word (most frequent word will have lower weight while less frequent word will have higher weight due to the relevancy / importance)\n",
    "</div>  \n",
    "\n",
    "\n",
    "* To filter out useless data \n",
    "\n",
    "    `stopwords.words()`\n",
    "<div class=\"alert alert-success\">  \n",
    "A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that will be filtered from the text to process accordingly.\n",
    "We do not want these words to take up the processing time and memory when running a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all the numeric values from the texts\n",
    "#Convert all the texts to lowercase\n",
    "data['cleaned0'] = data['text'].apply(lambda x: \" \".join([i for i in re.sub(\"[^a-zA-Z]\",\" \",x).split()]).lower())\n",
    "#Normalise the word to base form\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "data['cleaned'] = data['cleaned0'].apply(lambda i: wnl.lemmatize(i) if wnl.lemmatize(i).endswith('e') else porter.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>VisitedDealer</th>\n",
       "      <th>OtherDealerSatisfaction</th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>...</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v73</th>\n",
       "      <th>v80</th>\n",
       "      <th>v81</th>\n",
       "      <th>v90</th>\n",
       "      <th>v97</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned0</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45393</th>\n",
       "      <td>93087</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>They were helpful and friendly.</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>They were helpful and friendly.</td>\n",
       "      <td>they were helpful and friendly</td>\n",
       "      <td>they were helpful and friendli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45394</th>\n",
       "      <td>93089</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>It was not easy to take a test drive.</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It was not easy to take a test drive.</td>\n",
       "      <td>it was not easy to take a test drive</td>\n",
       "      <td>it was not easy to take a test drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45395</th>\n",
       "      <td>93090</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>Sales man very keen to sell me the car and exp...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales man very keen to sell me the car and exp...</td>\n",
       "      <td>sales man very keen to sell me the car and exp...</td>\n",
       "      <td>sales man very keen to sell me the car and exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45396</th>\n",
       "      <td>93091</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>i own one already</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i own one already</td>\n",
       "      <td>i own one already</td>\n",
       "      <td>i own one alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45397</th>\n",
       "      <td>93092</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>I wasn`t happy with dealer.</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I wasn`t happy with dealer.</td>\n",
       "      <td>i wasn t happy with dealer</td>\n",
       "      <td>i wasn t happy with deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45398</th>\n",
       "      <td>93094</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>The salesperson was very pushy and said he was...</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The salesperson was very pushy and said he was...</td>\n",
       "      <td>the salesperson was very pushy and said he was...</td>\n",
       "      <td>the salesperson was very pushy and said he was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45399</th>\n",
       "      <td>93095</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>Not as knowledgeable about the vehicle.</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not as knowledgeable about the vehicle.</td>\n",
       "      <td>not as knowledgeable about the vehicle</td>\n",
       "      <td>not as knowledgeable about the vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45400</th>\n",
       "      <td>93097</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>did not try to oversell or be pushey and gave ...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>did not try to oversell or be pushey and gave ...</td>\n",
       "      <td>did not try to oversell or be pushey and gave ...</td>\n",
       "      <td>did not try to oversell or be pushey and gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45401</th>\n",
       "      <td>93108</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>It took a while to be acknowledged</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It took a while to be acknowledged</td>\n",
       "      <td>it took a while to be acknowledged</td>\n",
       "      <td>it took a while to be acknowledg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>93111</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>While the dealer was polite and knowledgeable,...</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>While the dealer was polite and knowledgeable,...</td>\n",
       "      <td>while the dealer was polite and knowledgeable ...</td>\n",
       "      <td>while the dealer was polite and knowledgeable ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  QUARTER  VisitedDealer  OtherDealerSatisfaction  \\\n",
       "45393  93087        4             40                       10   \n",
       "45394  93089        4             23                        8   \n",
       "45395  93090        4             37                        9   \n",
       "45396  93091        4             28                       10   \n",
       "45397  93092        4             26                        6   \n",
       "45398  93094        4             23                        4   \n",
       "45399  93095        4             40                        8   \n",
       "45400  93097        4             46                       10   \n",
       "45401  93108        4              5                        7   \n",
       "45402  93111        4             42                        5   \n",
       "\n",
       "                                                Verbatim  C1    C2  C3  C4  \\\n",
       "45393                    They were helpful and friendly.   2   1.0 NaN NaN   \n",
       "45394              It was not easy to take a test drive.  61   NaN NaN NaN   \n",
       "45395  Sales man very keen to sell me the car and exp...   5   3.0 NaN NaN   \n",
       "45396                                  i own one already  31   NaN NaN NaN   \n",
       "45397                        I wasn`t happy with dealer.  60   NaN NaN NaN   \n",
       "45398  The salesperson was very pushy and said he was...  51   NaN NaN NaN   \n",
       "45399            Not as knowledgeable about the vehicle.  43   NaN NaN NaN   \n",
       "45400  did not try to oversell or be pushey and gave ...   7  16.0 NaN NaN   \n",
       "45401                 It took a while to be acknowledged  45   NaN NaN NaN   \n",
       "45402  While the dealer was polite and knowledgeable,...  52   NaN NaN NaN   \n",
       "\n",
       "       C5                        ...                          v71  v72  v73  \\\n",
       "45393 NaN                        ...                            0    0    0   \n",
       "45394 NaN                        ...                            0    0    0   \n",
       "45395 NaN                        ...                            0    0    0   \n",
       "45396 NaN                        ...                            0    0    0   \n",
       "45397 NaN                        ...                            0    0    0   \n",
       "45398 NaN                        ...                            0    0    0   \n",
       "45399 NaN                        ...                            0    0    0   \n",
       "45400 NaN                        ...                            0    0    0   \n",
       "45401 NaN                        ...                            0    0    0   \n",
       "45402 NaN                        ...                            0    0    0   \n",
       "\n",
       "       v80  v81  v90  v97                                               text  \\\n",
       "45393    0    0    0    0                    They were helpful and friendly.   \n",
       "45394    0    0    0    0              It was not easy to take a test drive.   \n",
       "45395    0    0    0    0  Sales man very keen to sell me the car and exp...   \n",
       "45396    0    0    0    0                                  i own one already   \n",
       "45397    0    0    0    0                        I wasn`t happy with dealer.   \n",
       "45398    0    0    0    0  The salesperson was very pushy and said he was...   \n",
       "45399    0    0    0    0            Not as knowledgeable about the vehicle.   \n",
       "45400    0    0    0    0  did not try to oversell or be pushey and gave ...   \n",
       "45401    0    0    0    0                 It took a while to be acknowledged   \n",
       "45402    0    0    0    0  While the dealer was polite and knowledgeable,...   \n",
       "\n",
       "                                                cleaned0  \\\n",
       "45393                     they were helpful and friendly   \n",
       "45394               it was not easy to take a test drive   \n",
       "45395  sales man very keen to sell me the car and exp...   \n",
       "45396                                  i own one already   \n",
       "45397                         i wasn t happy with dealer   \n",
       "45398  the salesperson was very pushy and said he was...   \n",
       "45399             not as knowledgeable about the vehicle   \n",
       "45400  did not try to oversell or be pushey and gave ...   \n",
       "45401                 it took a while to be acknowledged   \n",
       "45402  while the dealer was polite and knowledgeable ...   \n",
       "\n",
       "                                                 cleaned  \n",
       "45393                     they were helpful and friendli  \n",
       "45394               it was not easy to take a test drive  \n",
       "45395  sales man very keen to sell me the car and exp...  \n",
       "45396                                  i own one alreadi  \n",
       "45397                           i wasn t happy with deal  \n",
       "45398  the salesperson was very pushy and said he was...  \n",
       "45399             not as knowledgeable about the vehicle  \n",
       "45400  did not try to oversell or be pushey and gave ...  \n",
       "45401                   it took a while to be acknowledg  \n",
       "45402  while the dealer was polite and knowledgeable ...  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lack of time, from the 49 categories, I'm going to select 2 categories (v1,v2) with positive comments and another 2 (v45,v46) with negative comments to build 4 separate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v45</th>\n",
       "      <th>v46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38486</td>\n",
       "      <td>40018</td>\n",
       "      <td>42946</td>\n",
       "      <td>43101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6917</td>\n",
       "      <td>5385</td>\n",
       "      <td>2457</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1     v2    v45    v46\n",
       "0  38486  40018  42946  43101\n",
       "1   6917   5385   2457   2302"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the summary for each category\n",
    "data[['v1','v2','v45', 'v46']].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with imbalanced dataset?\n",
    "We can see that the data has imbalanced classes which will affect the 'accuracy' of a machine learning model, thus I choose to apply **down-sampling method** by removing the observations from the majority class (class=0) to prevent the its from dominating the learning algorithm. Observations with class=0 in this case have no significant impact to the feature variable (Comment from Customer), thus in my opinion, this is the easiest and simplest way in dealing with imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification for Model [v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply train test split for data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_v2 (31782,)\n",
      "y_train_v2 (31782,)\n",
      "X_test_v2 (13621,)\n",
      "y_test_v2 (13621,)\n",
      "\n",
      "\n",
      "Summary of y_train_v2\n",
      "\n",
      "\n",
      "0    28008\n",
      "1     3774\n",
      "Name: v2, dtype: int64\n",
      "\n",
      "\n",
      "Summary of y_test_v2\n",
      "\n",
      "\n",
      "0    12010\n",
      "1     1611\n",
      "Name: v2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(data['cleaned'], data['v2'], test_size=0.3, random_state=123)\n",
    "print('X_train_v2',X_train_v2.shape)\n",
    "print('y_train_v2',y_train_v2.shape)\n",
    "print('X_test_v2',X_test_v2.shape)\n",
    "print('y_test_v2',y_test_v2.shape)\n",
    "print(\"\\n\")\n",
    "print('Summary of y_train_v2')\n",
    "print(\"\\n\")\n",
    "print(pd.Series.value_counts(y_train_v2))\n",
    "print(\"\\n\")\n",
    "print('Summary of y_test_v2')\n",
    "print(\"\\n\")\n",
    "print(pd.Series.value_counts(y_test_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Down-Sampling method on majority class to training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31782, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    28008\n",
       "1     3774\n",
       "Name: v2, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine X_train and y_train for resampling\n",
    "Trainingdata_downsampled = pd.concat([X_train_v2, y_train_v2], axis=1)\n",
    "print(Trainingdata_downsampled.shape)\n",
    "Trainingdata_downsampled['v2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingdata_v2_majority (28008, 2)\n",
      "Trainingdata_v2_minority (3774, 2)\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "Trainingdata_v2_majority = Trainingdata_downsampled[Trainingdata_downsampled.v2==0]\n",
    "Trainingdata_v2_minority = Trainingdata_downsampled[Trainingdata_downsampled.v2==1]\n",
    "print('Trainingdata_v2_majority',Trainingdata_v2_majority.shape)\n",
    "print('Trainingdata_v2_minority',Trainingdata_v2_minority.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3774\n",
       "0    3774\n",
       "Name: v2, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "Trainingdata_v2_majority_downsampled = resample(Trainingdata_v2_majority, \n",
    "                                                replace=False,    # sample without replacement (cause we have many data to select - no need replace)\n",
    "                                                n_samples=3774,     # to match minority class\n",
    "                                                random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "Trainingdata_v2_downsampled = pd.concat([Trainingdata_v2_majority_downsampled, Trainingdata_v2_minority])\n",
    " \n",
    "# Display new class counts\n",
    "Trainingdata_v2_downsampled.v2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_v2 (7548,)\n",
      "y_train_v2 (7548,)\n",
      "Summary of y_train_v2\n",
      "\n",
      "\n",
      "1    3774\n",
      "0    3774\n",
      "Name: v2, dtype: int64\n",
      "\n",
      "\n",
      "Summary of y_test_v2\n",
      "\n",
      "\n",
      "0    12010\n",
      "1     1611\n",
      "Name: v2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Split training data after resampling \n",
    "X_train_v2 = Trainingdata_v2_downsampled['cleaned']\n",
    "y_train_v2 = Trainingdata_v2_downsampled['v2']\n",
    "print('X_train_v2',X_train_v2.shape)\n",
    "print('y_train_v2',y_train_v2.shape)\n",
    "\n",
    "print('Summary of y_train_v2')\n",
    "print(\"\\n\")\n",
    "print(pd.Series.value_counts(y_train_v2))\n",
    "print(\"\\n\")\n",
    "print('Summary of y_test_v2')\n",
    "print(\"\\n\")\n",
    "print(pd.Series.value_counts(y_test_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Multinomial Naive Bayes Classifier\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline1 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('nb', MultinomialNB())])\n",
    "\n",
    "#Pipeline: To assemble several steps to be cross-validated together\n",
    "#ngram_range: \n",
    "##Default 1,1: to consider every single word as a separate feature\n",
    "##using   1,2: to look at every separate word and also to look at a pair of 2 words \n",
    "               #to prevent stuff like this- \n",
    "               #E.g. the service in this dealer is not good \n",
    "               #if using 1,1, the algorithms will define as the customer is having good experience in this dealership, \n",
    "               #with 1,2: will consider this comment is actually bad\n",
    "\n",
    "model1 = pipeline1.fit(X_train_v2, y_train_v2)\n",
    "labels1 = model1.predict(X_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes Classifier on training set: 0.96\n",
      "Accuracy of Multinomial Naive Bayes Classifier on test set: 0.83\n",
      "\n",
      "Confusion matrix :\n",
      " [[9792 2218]\n",
      " [ 158 1453]]\n",
      "\n",
      "\n",
      "Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.82      0.89     12010\n",
      "          1       0.40      0.90      0.55      1611\n",
      "\n",
      "avg / total       0.91      0.83      0.85     13621\n",
      "\n",
      "ROC Curve\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGMK/T/Qztnac0ra3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218288968d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to make prediction\n",
    "y_pred_1 = model1.predict(X_test_v2)\n",
    "\n",
    "print('Accuracy of Multinomial Naive Bayes Classifier on training set: {:.2f}'\n",
    "     .format(model1.score(X_train_v2, y_train_v2)))\n",
    "print('Accuracy of Multinomial Naive Bayes Classifier on test set: {:.2f}'\n",
    "     .format(model1.score(X_test_v2, y_test_v2)))\n",
    "print('\\nConfusion matrix :\\n',confusion_matrix(y_test_v2, y_pred_1))\n",
    "print('\\n\\nClassification report :\\n\\n', classification_report(y_test_v2, y_pred_1))\n",
    "\n",
    "\n",
    "fpr1, tpr1, thresholds = roc_curve(y_test_v2, y_pred_1, pos_label=1)\n",
    "auc_result1 = auc(fpr1, tpr1)\n",
    "print('ROC Curve')\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr1, tpr1, label='area = {0:0.2f}'.format(auc_result1))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords\n",
      "MultinomialNB: drive test knowledgeable sales friendly helpful staff friendly help friendly helpful help\n"
     ]
    }
   ],
   "source": [
    "#to show the top feature names \n",
    "vectorizer1 = model1.named_steps['vect']\n",
    "clf1 = model1.named_steps['nb']\n",
    "feature_names = vectorizer1.get_feature_names()\n",
    "feature_names = np.asarray(feature_names)\n",
    "target_names = ['MultinomialNB']\n",
    "print(\"top 10 keywords\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top = np.argsort(clf1.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names[top])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression\n",
    "Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_mean_score: 0.9356129780244874\n",
      "baseline_std_score: 0.008405864783820768\n",
      "-----------\n",
      "grid_search_best_score 0.9479332273449921\n",
      "grid_search_best_parameters {'log__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline2 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('log', LogisticRegression())])\n",
    "\n",
    "scores2 = cross_val_score(pipeline2, X_train_v2, y_train_v2, cv=5)\n",
    "#Using K -fold cross-validation to partition training dataset so that the algorithms of our model will run several times. \n",
    "#Each time will choose a part as training data and another part as testing data to get the cross validation scores each time. \n",
    "#This method will overcome overfitting as we do our validation before any tuning on our training data.\n",
    "\n",
    "# To get baseline on the mean scores from cross-validation (cv=5)\n",
    "mean2 = scores2.mean()\n",
    "std2 = scores2.std()\n",
    "print('baseline_mean_score:',mean2)\n",
    "print('baseline_std_score:',std2)\n",
    "\n",
    "# Tuning parameters\n",
    "grid2 = {'log__penalty': ['l1', 'l2']}\n",
    "\n",
    "grid_search2 = GridSearchCV(pipeline2, param_grid=grid2, cv=5)\n",
    "\n",
    "grid_search2.fit(X_train_v2, y_train_v2)\n",
    "print(\"-----------\")\n",
    "print('grid_search_best_score', grid_search2.best_score_)\n",
    "print('grid_search_best_parameters',grid_search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to apply the best model\n",
    "pipeline2_best = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('log', LogisticRegression(penalty='l1'))])\n",
    "model2_best = pipeline2_best.fit(X_train_v2, y_train_v2)\n",
    "labels2_best = model2_best.predict(X_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistics Regression on training set: 0.94\n",
      "Accuracy of Logistics Regression on test set: 0.96\n",
      "\n",
      "Confusion matrix :\n",
      " [[11590   420]\n",
      " [  115  1496]]\n",
      "\n",
      "\n",
      "Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98     12010\n",
      "          1       0.78      0.93      0.85      1611\n",
      "\n",
      "avg / total       0.97      0.96      0.96     13621\n",
      "\n",
      "ROC Curve\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBWOMMR6WFIwxxnhYUjDGGOPx/8l8dGB+seIBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21814280518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to make prediction\n",
    "y_pred_2_best = model2_best.predict(X_test_v2)\n",
    "\n",
    "print('Accuracy of Logistics Regression on training set: {:.2f}'\n",
    "     .format(model2_best.score(X_train_v2, y_train_v2)))\n",
    "print('Accuracy of Logistics Regression on test set: {:.2f}'\n",
    "     .format(model2_best.score(X_test_v2, y_test_v2)))\n",
    "print('\\nConfusion matrix :\\n',confusion_matrix(y_test_v2, y_pred_2_best))\n",
    "print('\\n\\nClassification report :\\n\\n', classification_report(y_test_v2, y_pred_2_best))\n",
    "\n",
    "\n",
    "fpr2, tpr2, thresholds = roc_curve(y_test_v2, y_pred_2_best, pos_label=1)\n",
    "auc_result2 = auc(fpr2, tpr2)\n",
    "print('ROC Curve')\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr2, tpr2, label='area = {0:0.2f}'.format(auc_result2))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords\n",
      "LogisticRegression: accomod respectful accommod assist accomodating helped helpfull help accommodating helpful\n"
     ]
    }
   ],
   "source": [
    "#to show the top feature names \n",
    "vectorizer2 = model2_best.named_steps['vect']\n",
    "clf2 = model2_best.named_steps['log']\n",
    "feature_names2 = vectorizer2.get_feature_names()\n",
    "feature_names2 = np.asarray(feature_names2)\n",
    "target_names = ['LogisticRegression']\n",
    "print(\"top 10 keywords\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top2 = np.argsort(clf2.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names2[top2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent \n",
    "Stochastic Gradient Descent Classifier can optimize the same cost function as Linear Support Vector Machine by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_mean_score: 0.948065592776714\n",
      "baseline_std_score: 0.008930995849573945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "grid_search_best_score 0.9507154213036566\n",
      "grid_search_best_parameters {'sgd__class_weight': 'balanced', 'sgd__loss': 'hinge', 'sgd__penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipeline3 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('sgd', SGDClassifier())])\n",
    "\n",
    "scores3 = cross_val_score(pipeline3, X_train_v2, y_train_v2, cv=5)\n",
    "\n",
    "# To get baseline on the mean scores from cross-validation (cv=5)\n",
    "mean3 = scores3.mean()\n",
    "std3 = scores3.std()\n",
    "print('baseline_mean_score:',mean3)\n",
    "print('baseline_std_score:',std3)\n",
    "\n",
    "# Tuning parameters\n",
    "grid3 = {'sgd__penalty': ['l1','l2'],\n",
    "         'sgd__loss': ['modified_huber','hinge','log'],\n",
    "         'sgd__class_weight': ['balanced',None]}\n",
    "\n",
    "\n",
    "grid_search3 = GridSearchCV(pipeline3, param_grid=grid3, cv=5)\n",
    "\n",
    "grid_search3.fit(X_train_v2, y_train_v2)\n",
    "print(\"-----------\")\n",
    "print('grid_search_best_score', grid_search3.best_score_)\n",
    "print('grid_search_best_parameters',grid_search3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SiowHui.Chong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#to apply the best model\n",
    "pipeline3_best = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('sgd', SGDClassifier(penalty='l1',loss='hinge',class_weight='balanced'))])\n",
    "model3_best = pipeline3_best.fit(X_train_v2, y_train_v2)\n",
    "labels3_best = model3_best.predict(X_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD on training set: 0.96\n",
      "Accuracy of SGD on test set: 0.96\n",
      "\n",
      "Confusion matrix :\n",
      " [[11569   441]\n",
      " [   90  1521]]\n",
      "\n",
      "\n",
      "Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.98     12010\n",
      "          1       0.78      0.94      0.85      1611\n",
      "\n",
      "avg / total       0.97      0.96      0.96     13621\n",
      "\n",
      "ROC Curve\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2182b226c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to make prediction\n",
    "y_pred_3_best = model3_best.predict(X_test_v2)\n",
    "\n",
    "print('Accuracy of SGD on training set: {:.2f}'\n",
    "     .format(model3_best.score(X_train_v2, y_train_v2)))\n",
    "print('Accuracy of SGD on test set: {:.2f}'\n",
    "     .format(model3_best.score(X_test_v2, y_test_v2)))\n",
    "print('\\nConfusion matrix :\\n',confusion_matrix(y_test_v2, y_pred_3_best))\n",
    "print('\\n\\nClassification report :\\n\\n', classification_report(y_test_v2, y_pred_3_best))\n",
    "\n",
    "\n",
    "fpr3, tpr3, thresholds = roc_curve(y_test_v2, y_pred_3_best, pos_label=1)\n",
    "auc_result3 = auc(fpr3, tpr3)\n",
    "print('ROC Curve')\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr3, tpr3, label='area = {0:0.2f}'.format(auc_result3))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords\n",
      "SGDClassifier: willing help respectful accommod helped assist helpfull accomodating help accommodating helpful\n"
     ]
    }
   ],
   "source": [
    "#to show the top feature names \n",
    "vectorizer3 = model3_best.named_steps['vect']\n",
    "clf3 = model3_best.named_steps['sgd']\n",
    "feature_names3 = vectorizer3.get_feature_names()\n",
    "feature_names3 = np.asarray(feature_names3)\n",
    "target_names = ['SGDClassifier']\n",
    "print(\"top 10 keywords\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top3 = np.argsort(clf3.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names3[top3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_mean_score: 0.919183867057811\n",
      "baseline_std_score: 0.012318667440356807\n",
      "-----------\n",
      "grid_search_best_score 0.9362745098039216\n",
      "grid_search_best_parameters {'rf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline4 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('rf', RandomForestClassifier())])\n",
    "\n",
    "scores4 = cross_val_score(pipeline4, X_train_v2, y_train_v2, cv=5)\n",
    "\n",
    "# To get baseline on the mean scores from cross-validation (cv=5)\n",
    "mean4 = scores4.mean()\n",
    "std4 = scores4.std()\n",
    "print('baseline_mean_score:',mean4)\n",
    "print('baseline_std_score:',std4)\n",
    "\n",
    "# Tuning parameters\n",
    "grid4 = {'rf__n_estimators': [10,20,50]}\n",
    "\n",
    "\n",
    "grid_search4 = GridSearchCV(pipeline4, param_grid=grid4, cv=5)\n",
    "\n",
    "grid_search4.fit(X_train_v2, y_train_v2)\n",
    "print(\"-----------\")\n",
    "print('grid_search_best_score', grid_search4.best_score_)\n",
    "print('grid_search_best_parameters',grid_search4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to apply the best model\n",
    "pipeline4_best = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), stop_words=\"english\")),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('rf', RandomForestClassifier(n_estimators=50))])\n",
    "model4_best = pipeline4_best.fit(X_train_v2, y_train_v2)\n",
    "labels4_best = model4_best.predict(X_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on training set: 1.00\n",
      "Accuracy of Random Forest on test set: 0.97\n",
      "\n",
      "Confusion matrix :\n",
      " [[11731   279]\n",
      " [  156  1455]]\n",
      "\n",
      "\n",
      "Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98     12010\n",
      "          1       0.84      0.90      0.87      1611\n",
      "\n",
      "avg / total       0.97      0.97      0.97     13621\n",
      "\n",
      "ROC Curve\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2182f6119b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to make prediction\n",
    "y_pred_4_best = model4_best.predict(X_test_v2)\n",
    "\n",
    "print('Accuracy of Random Forest on training set: {:.2f}'\n",
    "     .format(model4_best.score(X_train_v2, y_train_v2)))\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'\n",
    "     .format(model4_best.score(X_test_v2, y_test_v2)))\n",
    "print('\\nConfusion matrix :\\n',confusion_matrix(y_test_v2, y_pred_4_best))\n",
    "print('\\n\\nClassification report :\\n\\n', classification_report(y_test_v2, y_pred_4_best))\n",
    "\n",
    "\n",
    "fpr4, tpr4, thresholds = roc_curve(y_test_v2, y_pred_4_best, pos_label=1)\n",
    "auc_result4 = auc(fpr4, tpr4)\n",
    "print('ROC Curve')\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr4, tpr4, label='area = {0:0.2f}'.format(auc_result4))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./Data/Model-v2.JPG\", width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose: Logistic Regression: Simple and Fast with high accuracy and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model1.predict(['Staff I dealt with was welcoming, easy to deal with as was willing to look at other options to try and assist.']))\n",
    "print(model2_best.predict(['Staff I dealt with was welcoming, easy to deal with as was willing to look at other options to try and assist.']))\n",
    "print(model3_best.predict(['Staff I dealt with was welcoming, easy to deal with as was willing to look at other options to try and assist.']))\n",
    "print(model4_best.predict(['Staff I dealt with was welcoming, easy to deal with as was willing to look at other options to try and assist.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(model1.predict(['They were very obliging showed through the vehicle and took me for test drive but my wife felt more comfortable driving smaller sedan']))\n",
    "print(model2_best.predict(['They were very obliging showed through the vehicle and took me for test drive but my wife felt more comfortable driving smaller sedan']))\n",
    "print(model3_best.predict(['They were very obliging showed through the vehicle and took me for test drive but my wife felt more comfortable driving smaller sedan']))\n",
    "print(model4_best.predict(['They were very obliging showed through the vehicle and took me for test drive but my wife felt more comfortable driving smaller sedan']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model1.predict(['They were really engaged. Went out of their way.  MakeX were arrogant for wnat of a better word.']))\n",
    "print(model2_best.predict(['They were really engaged. Went out of their way.  MakeX were arrogant for wnat of a better word.']))\n",
    "print(model3_best.predict(['They were really engaged. Went out of their way.  MakeX were arrogant for wnat of a better word.']))\n",
    "print(model4_best.predict(['They were really engaged. Went out of their way.  MakeX were arrogant for wnat of a better word.']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
